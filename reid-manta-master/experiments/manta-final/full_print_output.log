========================================
Date: 2022-12-07 15:30:02.812870 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:data/3_manta_unified
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from data/3_manta_unified
Found 0 files
Read 0 files from 0 classes
========================================
Date: 2022-12-07 15:31:03.954562 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:data/3_manta_unified
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from data/3_manta_unified
Found 0 files
Read 0 files from 0 classes
========================================
Date: 2022-12-07 15:44:39.622464 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:examples/manta-demo/db_localised
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from examples/manta-demo/db_localised
Found 5594 files
1000 images read
2000 images read
3000 images read
4000 images read
5000 images read
Read 5594 files from 7 classes
X shape: (5594, 300, 300, 3)
Labels shape: (5594,)
Label encoding:  {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6'}
Splitting dataset of size: 5594
Shape of train set : (4302, 300, 300, 3), shape of valid set: (1292, 300, 300, 3),
train labels: (4302,), valid labels: (1292,)
Dataset: train
name: train
n_samples: 4302
samples_shape: (300, 300, 3)
n_unique_labels: 5
unique_labels: [1 3 4 5 6]
min_samples: 642
max_samples: 1006
average_samples: 860.0
std_dev: 141.37
Dataset: valid
name: valid
n_samples: 1292
samples_shape: (300, 300, 3)
n_unique_labels: 2
unique_labels: [0 2]
min_samples: 498
max_samples: 794
average_samples: 646.0
std_dev: 148.0
========================================
Date: 2022-12-07 15:46:51.964859 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:examples/manta-demo/db_localised
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from examples/manta-demo/db_localised
Found 5594 files
1000 images read
2000 images read
3000 images read
4000 images read
5000 images read
Read 5594 files from 7 classes
X shape: (5594, 300, 300, 3)
Labels shape: (5594,)
Label encoding:  {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6'}
Splitting dataset of size: 5594
Shape of train set : (4302, 300, 300, 3), shape of valid set: (1292, 300, 300, 3),
train labels: (4302,), valid labels: (1292,)
Dataset: train
name: train
n_samples: 4302
samples_shape: (300, 300, 3)
n_unique_labels: 5
unique_labels: [1 3 4 5 6]
min_samples: 642
max_samples: 1006
average_samples: 860.0
std_dev: 141.37
Dataset: valid
name: valid
n_samples: 1292
samples_shape: (300, 300, 3)
n_unique_labels: 2
unique_labels: [0 2]
min_samples: 498
max_samples: 794
average_samples: 646.0
std_dev: 148.0
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5

   16384/87910968 [..............................] - ETA: 30s
   65536/87910968 [..............................] - ETA: 1:18
  229376/87910968 [..............................] - ETA: 41s 
  581632/87910968 [..............................] - ETA: 23s
  950272/87910968 [..............................] - ETA: 19s
 1310720/87910968 [..............................] - ETA: 17s
 1687552/87910968 [..............................] - ETA: 15s
 2064384/87910968 [..............................] - ETA: 15s
 2424832/87910968 [..............................] - ETA: 14s
 2801664/87910968 [..............................] - ETA: 14s
 3178496/87910968 [>.............................] - ETA: 13s
 3555328/87910968 [>.............................] - ETA: 13s
 3932160/87910968 [>.............................] - ETA: 13s
 4308992/87910968 [>.............................] - ETA: 12s
 4685824/87910968 [>.............................] - ETA: 12s
 5062656/87910968 [>.............................] - ETA: 12s
 5439488/87910968 [>.............................] - ETA: 12s
 5816320/87910968 [>.............................] - ETA: 12s
 6193152/87910968 [=>............................] - ETA: 12s
 6569984/87910968 [=>............................] - ETA: 12s
 6946816/87910968 [=>............................] - ETA: 11s
 7323648/87910968 [=>............................] - ETA: 11s
 7700480/87910968 [=>............................] - ETA: 11s
 8077312/87910968 [=>............................] - ETA: 11s
 8454144/87910968 [=>............................] - ETA: 11s
 8830976/87910968 [==>...........................] - ETA: 11s
 9207808/87910968 [==>...........................] - ETA: 11s
 9568256/87910968 [==>...........................] - ETA: 11s
 9945088/87910968 [==>...........................] - ETA: 11s
10321920/87910968 [==>...........................] - ETA: 11s
10698752/87910968 [==>...........................] - ETA: 11s
11059200/87910968 [==>...........................] - ETA: 11s
11436032/87910968 [==>...........................] - ETA: 10s
11812864/87910968 [===>..........................] - ETA: 10s
12189696/87910968 [===>..........................] - ETA: 10s
12566528/87910968 [===>..........................] - ETA: 10s
12943360/87910968 [===>..........................] - ETA: 10s
13320192/87910968 [===>..........................] - ETA: 10s
13697024/87910968 [===>..........................] - ETA: 10s
14073856/87910968 [===>..........................] - ETA: 10s
14450688/87910968 [===>..........................] - ETA: 10s
14827520/87910968 [====>.........................] - ETA: 10s
15204352/87910968 [====>.........................] - ETA: 10s
15581184/87910968 [====>.........................] - ETA: 10s
15958016/87910968 [====>.........................] - ETA: 10s
16334848/87910968 [====>.........................] - ETA: 10s
16711680/87910968 [====>.........................] - ETA: 10s
17088512/87910968 [====>.........................] - ETA: 9s 
17465344/87910968 [====>.........................] - ETA: 9s
17842176/87910968 [=====>........................] - ETA: 9s
18219008/87910968 [=====>........................] - ETA: 9s
18595840/87910968 [=====>........................] - ETA: 9s
18972672/87910968 [=====>........................] - ETA: 9s
19349504/87910968 [=====>........................] - ETA: 9s
19726336/87910968 [=====>........................] - ETA: 9s
20103168/87910968 [=====>........................] - ETA: 9s
20480000/87910968 [=====>........................] - ETA: 9s
20856832/87910968 [======>.......................] - ETA: 9s
21233664/87910968 [======>.......................] - ETA: 9s
21610496/87910968 [======>.......................] - ETA: 9s
21987328/87910968 [======>.......................] - ETA: 9s
22364160/87910968 [======>.......................] - ETA: 9s
22740992/87910968 [======>.......................] - ETA: 9s
23117824/87910968 [======>.......................] - ETA: 9s
23494656/87910968 [=======>......................] - ETA: 8s
23707648/87910968 [=======>......................] - ETA: 9s
24002560/87910968 [=======>......................] - ETA: 8s
24166400/87910968 [=======>......................] - ETA: 9s
24231936/87910968 [=======>......................] - ETA: 9s
24395776/87910968 [=======>......................] - ETA: 9s
24674304/87910968 [=======>......................] - ETA: 9s
25411584/87910968 [=======>......................] - ETA: 9s
26017792/87910968 [=======>......................] - ETA: 9s
27017216/87910968 [========>.....................] - ETA: 9s
27394048/87910968 [========>.....................] - ETA: 8s
27770880/87910968 [========>.....................] - ETA: 8s
28147712/87910968 [========>.....................] - ETA: 8s
28524544/87910968 [========>.....................] - ETA: 8s
28901376/87910968 [========>.....................] - ETA: 8s
29278208/87910968 [========>.....................] - ETA: 8s
29655040/87910968 [=========>....................] - ETA: 8s
30015488/87910968 [=========>....................] - ETA: 8s
30392320/87910968 [=========>....................] - ETA: 8s
30769152/87910968 [=========>....................] - ETA: 8s
31145984/87910968 [=========>....................] - ETA: 8s
31522816/87910968 [=========>....................] - ETA: 8s
31899648/87910968 [=========>....................] - ETA: 8s
32276480/87910968 [==========>...................] - ETA: 8s
32653312/87910968 [==========>...................] - ETA: 8s
33030144/87910968 [==========>...................] - ETA: 8s
33406976/87910968 [==========>...................] - ETA: 7s
33783808/87910968 [==========>...................] - ETA: 7s
34160640/87910968 [==========>...................] - ETA: 7s
34537472/87910968 [==========>...................] - ETA: 7s
34914304/87910968 [==========>...................] - ETA: 7s
35291136/87910968 [===========>..................] - ETA: 7s
35553280/87910968 [===========>..................] - ETA: 7s
35766272/87910968 [===========>..................] - ETA: 7s
35962880/87910968 [===========>..................] - ETA: 7s
36159488/87910968 [===========>..................] - ETA: 7s
36536320/87910968 [===========>..................] - ETA: 7s
36913152/87910968 [===========>..................] - ETA: 7s
37289984/87910968 [===========>..................] - ETA: 7s
37666816/87910968 [===========>..................] - ETA: 7s
38043648/87910968 [===========>..................] - ETA: 7s
38420480/87910968 [============>.................] - ETA: 7s
38797312/87910968 [============>.................] - ETA: 7s
39174144/87910968 [============>.................] - ETA: 7s
39550976/87910968 [============>.................] - ETA: 7s
39927808/87910968 [============>.................] - ETA: 7s
40304640/87910968 [============>.................] - ETA: 6s
40681472/87910968 [============>.................] - ETA: 6s
41058304/87910968 [=============>................] - ETA: 6s
41435136/87910968 [=============>................] - ETA: 6s
41811968/87910968 [=============>................] - ETA: 6s
42188800/87910968 [=============>................] - ETA: 6s
42565632/87910968 [=============>................] - ETA: 6s
42942464/87910968 [=============>................] - ETA: 6s
43319296/87910968 [=============>................] - ETA: 6s
43696128/87910968 [=============>................] - ETA: 6s
44072960/87910968 [==============>...............] - ETA: 6s
44449792/87910968 [==============>...............] - ETA: 6s
44826624/87910968 [==============>...............] - ETA: 6s
45203456/87910968 [==============>...............] - ETA: 6s
45580288/87910968 [==============>...............] - ETA: 6s
45957120/87910968 [==============>...............] - ETA: 6s
46333952/87910968 [==============>...............] - ETA: 6s
46710784/87910968 [==============>...............] - ETA: 5s
47087616/87910968 [===============>..............] - ETA: 5s
47464448/87910968 [===============>..............] - ETA: 5s
47841280/87910968 [===============>..............] - ETA: 5s
48218112/87910968 [===============>..............] - ETA: 5s
48594944/87910968 [===============>..............] - ETA: 5s
48971776/87910968 [===============>..............] - ETA: 5s
49348608/87910968 [===============>..............] - ETA: 5s
49725440/87910968 [===============>..............] - ETA: 5s
50102272/87910968 [================>.............] - ETA: 5s
50479104/87910968 [================>.............] - ETA: 5s
50855936/87910968 [================>.............] - ETA: 5s
51232768/87910968 [================>.............] - ETA: 5s
51609600/87910968 [================>.............] - ETA: 5s
51986432/87910968 [================>.............] - ETA: 5s
52363264/87910968 [================>.............] - ETA: 5s
52723712/87910968 [================>.............] - ETA: 5s
53100544/87910968 [=================>............] - ETA: 5s
53477376/87910968 [=================>............] - ETA: 4s
53854208/87910968 [=================>............] - ETA: 4s
54231040/87910968 [=================>............] - ETA: 4s
54607872/87910968 [=================>............] - ETA: 4s
54984704/87910968 [=================>............] - ETA: 4s
55361536/87910968 [=================>............] - ETA: 4s
55738368/87910968 [==================>...........] - ETA: 4s
56115200/87910968 [==================>...........] - ETA: 4s
56492032/87910968 [==================>...........] - ETA: 4s
56868864/87910968 [==================>...........] - ETA: 4s
57245696/87910968 [==================>...........] - ETA: 4s
57622528/87910968 [==================>...........] - ETA: 4s
57982976/87910968 [==================>...........] - ETA: 4s
58359808/87910968 [==================>...........] - ETA: 4s
58736640/87910968 [===================>..........] - ETA: 4s
59113472/87910968 [===================>..........] - ETA: 4s
59490304/87910968 [===================>..........] - ETA: 4s
59867136/87910968 [===================>..........] - ETA: 4s
60243968/87910968 [===================>..........] - ETA: 3s
60620800/87910968 [===================>..........] - ETA: 3s
60997632/87910968 [===================>..........] - ETA: 3s
61374464/87910968 [===================>..........] - ETA: 3s
61751296/87910968 [====================>.........] - ETA: 3s
62128128/87910968 [====================>.........] - ETA: 3s
62504960/87910968 [====================>.........] - ETA: 3s
62881792/87910968 [====================>.........] - ETA: 3s
63258624/87910968 [====================>.........] - ETA: 3s
63635456/87910968 [====================>.........] - ETA: 3s
64012288/87910968 [====================>.........] - ETA: 3s
64389120/87910968 [====================>.........] - ETA: 3s
64765952/87910968 [=====================>........] - ETA: 3s
65142784/87910968 [=====================>........] - ETA: 3s
65519616/87910968 [=====================>........] - ETA: 3s
65896448/87910968 [=====================>........] - ETA: 3s
66273280/87910968 [=====================>........] - ETA: 3s
66650112/87910968 [=====================>........] - ETA: 3s
67026944/87910968 [=====================>........] - ETA: 2s
67403776/87910968 [======================>.......] - ETA: 2s
67780608/87910968 [======================>.......] - ETA: 2s
68157440/87910968 [======================>.......] - ETA: 2s
68534272/87910968 [======================>.......] - ETA: 2s
68911104/87910968 [======================>.......] - ETA: 2s
69287936/87910968 [======================>.......] - ETA: 2s
69664768/87910968 [======================>.......] - ETA: 2s
70041600/87910968 [======================>.......] - ETA: 2s
70418432/87910968 [=======================>......] - ETA: 2s
70795264/87910968 [=======================>......] - ETA: 2s
71155712/87910968 [=======================>......] - ETA: 2s
71532544/87910968 [=======================>......] - ETA: 2s
71909376/87910968 [=======================>......] - ETA: 2s
72286208/87910968 [=======================>......] - ETA: 2s
72663040/87910968 [=======================>......] - ETA: 2s
73039872/87910968 [=======================>......] - ETA: 2s
73236480/87910968 [=======================>......] - ETA: 2s
73449472/87910968 [========================>.....] - ETA: 2s
73646080/87910968 [========================>.....] - ETA: 2s
73859072/87910968 [========================>.....] - ETA: 2s
74235904/87910968 [========================>.....] - ETA: 1s
74612736/87910968 [========================>.....] - ETA: 1s
74989568/87910968 [========================>.....] - ETA: 1s
75366400/87910968 [========================>.....] - ETA: 1s
75743232/87910968 [========================>.....] - ETA: 1s
76120064/87910968 [========================>.....] - ETA: 1s
76496896/87910968 [=========================>....] - ETA: 1s
76873728/87910968 [=========================>....] - ETA: 1s
77250560/87910968 [=========================>....] - ETA: 1s
77627392/87910968 [=========================>....] - ETA: 1s
78004224/87910968 [=========================>....] - ETA: 1s
78381056/87910968 [=========================>....] - ETA: 1s
78757888/87910968 [=========================>....] - ETA: 1s
79134720/87910968 [==========================>...] - ETA: 1s
79511552/87910968 [==========================>...] - ETA: 1s
79872000/87910968 [==========================>...] - ETA: 1s
80248832/87910968 [==========================>...] - ETA: 1s
80625664/87910968 [==========================>...] - ETA: 1s
81002496/87910968 [==========================>...] - ETA: 0s
81379328/87910968 [==========================>...] - ETA: 0s
81756160/87910968 [==========================>...] - ETA: 0s
82132992/87910968 [===========================>..] - ETA: 0s
82509824/87910968 [===========================>..] - ETA: 0s
82886656/87910968 [===========================>..] - ETA: 0s
83263488/87910968 [===========================>..] - ETA: 0s
83640320/87910968 [===========================>..] - ETA: 0s
84017152/87910968 [===========================>..] - ETA: 0s
84393984/87910968 [===========================>..] - ETA: 0s
84770816/87910968 [===========================>..] - ETA: 0s
85147648/87910968 [============================>.] - ETA: 0s
85524480/87910968 [============================>.] - ETA: 0s
85901312/87910968 [============================>.] - ETA: 0s
86278144/87910968 [============================>.] - ETA: 0s
86654976/87910968 [============================>.] - ETA: 0s
87031808/87910968 [============================>.] - ETA: 0s
87408640/87910968 [============================>.] - ETA: 0s
87785472/87910968 [============================>.] - ETA: 0s
87916544/87910968 [==============================] - 13s 0us/step

87924736/87910968 [==============================] - 13s 0us/step
Connecting layer 310 - mixed10
========================================
Date: 2022-12-07 15:49:56.161529 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:examples/manta-demo/db_localised
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from examples/manta-demo/db_localised
Found 5594 files
1000 images read
2000 images read
3000 images read
4000 images read
5000 images read
Read 5594 files from 7 classes
X shape: (5594, 300, 300, 3)
Labels shape: (5594,)
Label encoding:  {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6'}
Splitting dataset of size: 5594
Shape of train set : (4302, 300, 300, 3), shape of valid set: (1292, 300, 300, 3),
train labels: (4302,), valid labels: (1292,)
Dataset: train
name: train
n_samples: 4302
samples_shape: (300, 300, 3)
n_unique_labels: 5
unique_labels: [1 3 4 5 6]
min_samples: 642
max_samples: 1006
average_samples: 860.0
std_dev: 141.37
Dataset: valid
name: valid
n_samples: 1292
samples_shape: (300, 300, 3)
n_unique_labels: 2
unique_labels: [0 2]
min_samples: 498
max_samples: 794
average_samples: 646.0
std_dev: 148.0
Connecting layer 310 - mixed10
========================================
Date: 2022-12-07 15:54:09.448326 / Experiment id: manta-final
Config parameters:

   model:
        type:TripletLoss
        backend:InceptionV3
        connect_layer:-1
        precomp_feat:False
        frontend:glob_pool
        train_from_layer:0
        input_width:300
        input_height:300
        embedding_size:256
        loss:semi_hard_triplet
        n_poses:1
        average:False
        rotate_poses:False
        two_outputs:False
        perspective:False
   data:
        train_image_folder:examples/manta-demo/db_localised
        split_seed:777
   train:
        pretrained_weights:
        batch_size:32
        learning_rate:1e-05
        nb_epochs:400
        log_step:10
        distance:l2
        exp_dir:experiments
        exp_id:manta-final
        debug:False
        aug_rate:manta
        cl_per_batch:15
        sampl_per_class:5
        equal_k:True
        verbose:1
   evaluate:
        accuracy_at_k:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        move_to_dataset:2
        test_set:
        n_eval_epochs:20
        far_target:0.01
   general:
        stdout-file:True
   predict:
        db-emb:['examples/manta-demo/predict-emb']
   prod:
        prefix:manta-db
        output:examples/manta-demo/db_localised
        lfile:
        embeddings:examples/manta-demo/db_embs
        temp:examples/manta-demo
========================================
No test set. Splitting train set...
Reading files from examples/manta-demo/db_localised
Found 5594 files
1000 images read
2000 images read
3000 images read
4000 images read
5000 images read
Read 5594 files from 7 classes
X shape: (5594, 300, 300, 3)
Labels shape: (5594,)
Label encoding:  {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6'}
Splitting dataset of size: 5594
Shape of train set : (4302, 300, 300, 3), shape of valid set: (1292, 300, 300, 3),
train labels: (4302,), valid labels: (1292,)
Dataset: train
name: train
n_samples: 4302
samples_shape: (300, 300, 3)
n_unique_labels: 5
unique_labels: [1 3 4 5 6]
min_samples: 642
max_samples: 1006
average_samples: 860.0
std_dev: 141.37
Dataset: valid
name: valid
n_samples: 1292
samples_shape: (300, 300, 3)
n_unique_labels: 2
unique_labels: [0 2]
min_samples: 498
max_samples: 794
average_samples: 646.0
std_dev: 148.0
Connecting layer 310 - mixed10
